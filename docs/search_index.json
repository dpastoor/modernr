[
["index.html", "Modern R Solutions Current", " Modern R Solutions Devin Pastoor Current Please see the solutions below! "],
["introduction-to-ggplot2.html", "1 Introduction to ggplot2 1.1 XY Plots 1.2 Boxplots and Histograms", " 1 Introduction to ggplot2 library(PKPDmisc) library(PKPDdatasets) library(tidyverse) #&gt; Loading tidyverse: ggplot2 #&gt; Loading tidyverse: tibble #&gt; Loading tidyverse: tidyr #&gt; Loading tidyverse: readr #&gt; Loading tidyverse: purrr #&gt; Loading tidyverse: dplyr #&gt; Conflicts with tidy packages ---------------------------------------------- #&gt; filter(): dplyr, stats #&gt; lag(): dplyr, stats 1.1 XY Plots For concentration-time plots filter only OCC 1 from dapa_IV_oral (in PKPDdatasets) for subsequent plotting data1 &lt;- dapa_IV_oral %&gt;% filter(OCC == 1) Basic Concentration-Time plot (point and lines) data1 %&gt;% ggplot(aes(x = TIME, y = COBS, group = ID)) + geom_point() + geom_line() make points/lines bigger data1 %&gt;% ggplot(aes(x = TIME, y = COBS, group = ID)) + geom_point(size = 2.5) + geom_line(size = 1.1) add log transformation to y axis data1 %&gt;% ggplot(aes(x = TIME, y = COBS, group = ID)) + geom_point(size = 2.5) + geom_line(size = 1.1) + scale_y_log10() Add color by gender data1 %&gt;% ggplot(aes(x = TIME, y = COBS, group = ID, color = GENDER)) + geom_point(size = 2.5) + geom_line(size = 1.1) + scale_y_log10() BONUS: rename labels legend data1 %&gt;% ggplot(aes(x = TIME, y = COBS, group = ID, color = GENDER)) + geom_point(size = 2.5) + geom_line(size = 1.1) + scale_y_log10() + scale_color_discrete(labels = c(&quot;Male&quot;, &quot;Female&quot;)) BONUS: move legend to top right data1 %&gt;% ggplot(aes(x = TIME, y = COBS, group = ID, color = GENDER)) + geom_point(size = 2.5) + geom_line(size = 1.1) + scale_y_log10() + scale_color_discrete(labels = c(&quot;Male&quot;, &quot;Female&quot;)) + theme(legend.position = c(1, 1), legend.justification = c(1, 1)) facet by race Note, with facetting by race, the color becomes unnessary extra visual stimulus so we remove the color. data1 %&gt;% ggplot(aes(x = TIME, y = COBS, group = ID)) + geom_point(size = 2.5) + geom_line(size = 1.1) + scale_y_log10() + theme(legend.position = c(1, 1), legend.justification = c(1, 1)) + facet_wrap(~GENDER) BONUS: rename facet strips by name There are a couple ways of doing this: on the fly mutate the the values to labels # this is the only time you will see assigning to a column directly # in this workshop, we encourage to always use mutate to manage columns # in a dataframe, however as it has not been formally introduced we&#39;re # using base R here data1$GENDER &lt;- factor(data1$GENDER, levels = c(0, 1), labels = c(&quot;Male&quot;, &quot;Female&quot;)) data1 %&gt;% ggplot(aes(x = TIME, y = COBS, group = ID)) + geom_point(size = 2.5) + geom_line(size = 1.1) + scale_y_log10() + theme(legend.position = c(1, 1), legend.justification = c(1, 1)) + facet_wrap(~GENDER) Use facet_grid with the labeller argument data1 %&gt;% ggplot(aes(x = TIME, y = COBS, group = ID)) + geom_point(size = 2.5) + geom_line(size = 1.1) + scale_y_log10() + theme(legend.position = c(1, 1), legend.justification = c(1, 1)) + facet_grid(.~GENDER, labeller = label_both) color by weight data1 %&gt;% ggplot(aes(x = TIME, y = COBS, group = ID, color = WEIGHT)) + geom_point(size = 2.5) + geom_line(size = 1.1) + scale_y_log10() + theme(legend.position = c(1, 1), legend.justification = c(1, 1)) BONUS: rename axes data1 %&gt;% ggplot(aes(x = TIME, y = COBS, group = ID, color = WEIGHT)) + geom_point(size = 2.5) + geom_line(size = 1.1) + scale_y_log10() + theme(legend.position = c(1, 1), legend.justification = c(1, 1)) + labs(x = &quot;Time, hours&quot;, y = &quot;Concentration, ug/mL&quot;) 1.2 Boxplots and Histograms Histogram(s) of demographics # distinct is a dplyr verb - easiest way to subset data by the # first row in some combination. sid_data &lt;- data1 %&gt;% distinct(ID, .keep_all = TRUE) # single row per id data sid_data %&gt;% ggplot(aes(x = WEIGHT)) + geom_histogram(binwidth= 4, color=&quot;black&quot;, fill=&quot;white&quot;) add vertical line for median value ggplot(data = sid_data, aes(x = WEIGHT)) + geom_histogram(binwidth= 4, color=&quot;black&quot;, fill=&quot;white&quot;) + geom_vline(aes(xintercept = median(WEIGHT)), size= 2, color = &quot;red&quot;) devtools::session_info() #&gt; Session info ------------------------------------------------------------- #&gt; setting value #&gt; version R version 3.4.0 (2017-04-21) #&gt; system x86_64, mingw32 #&gt; ui RTerm #&gt; language (EN) #&gt; collate English_United States.1252 #&gt; tz Europe/Prague #&gt; date 2017-06-05 #&gt; Packages ----------------------------------------------------------------- #&gt; package * version date source #&gt; assertthat 0.2.0 2017-04-11 CRAN (R 3.4.0) #&gt; backports 1.1.0 2017-05-22 CRAN (R 3.4.0) #&gt; base * 3.4.0 2017-04-21 local #&gt; bindr 0.1 2016-11-13 CRAN (R 3.4.0) #&gt; bindrcpp * 0.1 2016-12-11 CRAN (R 3.4.0) #&gt; bookdown 0.4 2017-05-20 CRAN (R 3.4.0) #&gt; broom 0.4.2 2017-02-13 CRAN (R 3.4.0) #&gt; cellranger 1.1.0 2016-07-27 CRAN (R 3.4.0) #&gt; codetools 0.2-15 2016-10-05 CRAN (R 3.4.0) #&gt; colorspace 1.3-2 2016-12-14 CRAN (R 3.4.0) #&gt; compiler 3.4.0 2017-04-21 local #&gt; datasets * 3.4.0 2017-04-21 local #&gt; devtools 1.13.1 2017-05-13 CRAN (R 3.4.0) #&gt; digest 0.6.12 2017-01-27 CRAN (R 3.4.0) #&gt; dplyr * 0.6.0 2017-06-02 Github (tidyverse/dplyr@b064c4b) #&gt; evaluate 0.10 2016-10-11 CRAN (R 3.4.0) #&gt; forcats 0.2.0 2017-01-23 CRAN (R 3.4.0) #&gt; foreign 0.8-67 2016-09-13 CRAN (R 3.4.0) #&gt; ggplot2 * 2.2.1 2016-12-30 CRAN (R 3.4.0) #&gt; glue 1.0.0 2017-04-17 CRAN (R 3.4.0) #&gt; graphics * 3.4.0 2017-04-21 local #&gt; grDevices * 3.4.0 2017-04-21 local #&gt; grid 3.4.0 2017-04-21 local #&gt; gtable 0.2.0 2016-02-26 CRAN (R 3.4.0) #&gt; haven 1.0.0 2016-09-23 CRAN (R 3.4.0) #&gt; hms 0.3 2016-11-22 CRAN (R 3.4.0) #&gt; htmltools 0.3.6 2017-04-28 CRAN (R 3.4.0) #&gt; httr 1.2.1 2016-07-03 CRAN (R 3.4.0) #&gt; jsonlite 1.5 2017-06-01 CRAN (R 3.4.0) #&gt; knitr 1.16 2017-05-18 CRAN (R 3.4.0) #&gt; labeling 0.3 2014-08-23 CRAN (R 3.4.0) #&gt; lattice 0.20-35 2017-03-25 CRAN (R 3.4.0) #&gt; lazyeval 0.2.0 2016-06-12 CRAN (R 3.4.0) #&gt; lubridate 1.6.0 2016-09-13 CRAN (R 3.4.0) #&gt; magrittr 1.5 2014-11-22 CRAN (R 3.4.0) #&gt; memoise 1.1.0 2017-04-21 CRAN (R 3.4.0) #&gt; methods 3.4.0 2017-04-21 local #&gt; mnormt 1.5-5 2016-10-15 CRAN (R 3.4.0) #&gt; modelr 0.1.0 2016-08-31 CRAN (R 3.4.0) #&gt; munsell 0.4.3 2016-02-13 CRAN (R 3.4.0) #&gt; nlme 3.1-131 2017-02-06 CRAN (R 3.4.0) #&gt; parallel 3.4.0 2017-04-21 local #&gt; PKPDdatasets * 0.1.0 2017-06-02 Github (dpastoor/PKPDdatasets@9eaa831) #&gt; PKPDmisc * 1.0.0 2017-06-02 Github (dpastoor/PKPDmisc@23e1f49) #&gt; plyr 1.8.4 2016-06-08 CRAN (R 3.4.0) #&gt; psych 1.7.5 2017-05-03 CRAN (R 3.4.0) #&gt; purrr * 0.2.2.2 2017-05-11 CRAN (R 3.4.0) #&gt; R6 2.2.1 2017-05-10 CRAN (R 3.4.0) #&gt; Rcpp 0.12.11 2017-05-22 CRAN (R 3.4.0) #&gt; readr * 1.1.1 2017-05-16 CRAN (R 3.4.0) #&gt; readxl 1.0.0 2017-04-18 CRAN (R 3.4.0) #&gt; reshape2 1.4.2 2016-10-22 CRAN (R 3.4.0) #&gt; rlang 0.1.1 2017-05-18 CRAN (R 3.4.0) #&gt; rmarkdown 1.5.9000 2017-06-03 Github (rstudio/rmarkdown@ea515ef) #&gt; rprojroot 1.2 2017-01-16 CRAN (R 3.4.0) #&gt; rvest 0.3.2 2016-06-17 CRAN (R 3.4.0) #&gt; scales 0.4.1 2016-11-09 CRAN (R 3.4.0) #&gt; stats * 3.4.0 2017-04-21 local #&gt; stringi 1.1.5 2017-04-07 CRAN (R 3.4.0) #&gt; stringr 1.2.0 2017-02-18 CRAN (R 3.4.0) #&gt; tibble * 1.3.3 2017-05-28 CRAN (R 3.4.0) #&gt; tidyr * 0.6.3 2017-05-15 CRAN (R 3.4.0) #&gt; tidyverse * 1.1.1 2017-01-27 CRAN (R 3.4.0) #&gt; tools 3.4.0 2017-04-21 local #&gt; utils * 3.4.0 2017-04-21 local #&gt; withr 1.0.2 2016-06-20 CRAN (R 3.4.0) #&gt; xml2 1.1.1 2017-01-24 CRAN (R 3.4.0) #&gt; yaml 2.1.14 2016-11-12 CRAN (R 3.4.0) "],
["data-manipulation.html", "2 Data manipulation 2.1 DATA IMPORT 2.2 DATA MANIPULATION 2.3 Descriptive Statistics 2.4 average_obs", " 2 Data manipulation library(knitr) library(tidyverse) #&gt; Loading tidyverse: ggplot2 #&gt; Loading tidyverse: tibble #&gt; Loading tidyverse: tidyr #&gt; Loading tidyverse: readr #&gt; Loading tidyverse: purrr #&gt; Loading tidyverse: dplyr #&gt; Conflicts with tidy packages ---------------------------------------------- #&gt; filter(): dplyr, stats #&gt; lag(): dplyr, stats library(PKPDmisc) 2.1 DATA IMPORT Objectives: Import datasets and documents Perform basic data manipulation upon importing the data. pk_data &lt;- read_csv(&quot;../data/pk_data.csv&quot;) #&gt; Parsed with column specification: #&gt; cols( #&gt; ID = col_integer(), #&gt; TIME = col_double(), #&gt; DV = col_character(), #&gt; AMT = col_integer(), #&gt; DOSE = col_integer(), #&gt; FORM = col_character(), #&gt; SEX = col_character(), #&gt; WT = col_double(), #&gt; AGE = col_integer(), #&gt; RACE = col_character() #&gt; ) head(pk_data) #&gt; # A tibble: 6 x 10 #&gt; ID TIME DV AMT DOSE FORM SEX WT AGE RACE #&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 1 0.00 &lt;NA&gt; 100 100 IV Female 56.8 28 Hispanic #&gt; 2 1 0.25 1273.5 NA 100 IV Female 56.8 28 Hispanic #&gt; 3 1 0.50 995.38 NA 100 IV Female 56.8 28 Hispanic #&gt; 4 1 1.00 1254.7 NA 100 IV Female 56.8 28 Hispanic #&gt; 5 1 2.00 1037.6 NA 100 IV Female 56.8 28 Hispanic #&gt; 6 1 3.00 1135.4 NA 100 IV Female 56.8 28 Hispanic 2.2 DATA MANIPULATION The goals of this section: Use data manipulation tools to prepare the dataset for analysis Rename “DV” column as “COBS” pk_data_cobs &lt;- pk_data %&gt;% rename(COBS = DV) Perform the following tasks: Ensure that the following columns are numeric and not text: TIME, COBS, WT, AGE, AMT and DOSEs glimpse(pk_data_cobs) #&gt; Observations: 1,200 #&gt; Variables: 10 #&gt; $ ID &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, ... #&gt; $ TIME &lt;dbl&gt; 0.00, 0.25, 0.50, 1.00, 2.00, 3.00, 4.00, 6.00, 8.00, 12.... #&gt; $ COBS &lt;chr&gt; NA, &quot;1273.5&quot;, &quot;995.38&quot;, &quot;1254.7&quot;, &quot;1037.6&quot;, &quot;1135.4&quot;, &quot;10... #&gt; $ AMT &lt;int&gt; 100, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 100, NA,... #&gt; $ DOSE &lt;int&gt; 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 10... #&gt; $ FORM &lt;chr&gt; &quot;IV&quot;, &quot;IV&quot;, &quot;IV&quot;, &quot;IV&quot;, &quot;IV&quot;, &quot;IV&quot;, &quot;IV&quot;, &quot;IV&quot;, &quot;IV&quot;, &quot;IV... #&gt; $ SEX &lt;chr&gt; &quot;Female&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Female... #&gt; $ WT &lt;dbl&gt; 56.8, 56.8, 56.8, 56.8, 56.8, 56.8, 56.8, 56.8, 56.8, 56.... #&gt; $ AGE &lt;int&gt; 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 30, 30, 3... #&gt; $ RACE &lt;chr&gt; &quot;Hispanic&quot;, &quot;Hispanic&quot;, &quot;Hispanic&quot;, &quot;Hispanic&quot;, &quot;Hispanic... unique_non_numerics(pk_data_cobs$COBS) #&gt; [1] &quot;BQL&quot; Create a new column called BQLFLAG which takes a value of 0 if there is a numerical value in CObs and 1 if there is “BQL” in COBS. pk_data_cobs &lt;- pk_data_cobs %&gt;% mutate(BQLFLAG = ifelse(is.na(COBS), 0, ifelse(COBS == &quot;BQL&quot;, 1, 0)), NONNUMERICS = ifelse(COBS %in% unique_non_numerics(COBS), 1, 0), COBS = as_numeric(COBS)) #&gt; Warning in as_numeric(COBS): NAs introduced by coercion c. Create a new column called &quot;GENDER&quot; where: i. Female = 0 ii. Male = 1 d. Create a new column called RACEN where: i. Caucasian = 0 ii. Asian = 1 iii. Black = 2 iv. Hispanic = 3 pk_data_cobs &lt;- pk_data_cobs %&gt;% mutate( GENDER = factor(SEX, levels = c(0, 1), labels = c(&quot;Female&quot;, &quot;Male&quot;)), RACEN = ifelse(RACE == &quot;Caucasian&quot;, 0, ifelse(RACE == &quot;Asian&quot;, 1, ifelse(RACE == &quot;Black&quot;,2, ifelse(RACE == &quot;Hispanic&quot;, 3, -99))))) Create a new column called “IDF” - unique subject ID as combination of formulation and ID pk_data_cobs &lt;- pk_data_cobs %&gt;% mutate(IDF = paste(ID, FORM, sep = &quot;-&quot;)) Remove the following columns SEX RACE pk_data_output &lt;- pk_data_cobs %&gt;% select(-SEX, -RACE) head(pk_data_output) %&gt;% kable() ID TIME COBS AMT DOSE FORM WT AGE BQLFLAG NONNUMERICS GENDER RACEN IDF 1 0.00 NA 100 100 IV 56.8 28 0 0 NA 3 1-IV 1 0.25 1274 NA 100 IV 56.8 28 0 0 NA 3 1-IV 1 0.50 995 NA 100 IV 56.8 28 0 0 NA 3 1-IV 1 1.00 1255 NA 100 IV 56.8 28 0 0 NA 3 1-IV 1 2.00 1038 NA 100 IV 56.8 28 0 0 NA 3 1-IV 1 3.00 1135 NA 100 IV 56.8 28 0 0 NA 3 1-IV Save the above modifications as a new csv file write_csv(pk_data_output, &quot;../data/pk_data_output.csv&quot;) 2.3 Descriptive Statistics show a summary for all demographic columns # single row per id sid_pk_data &lt;- pk_data_cobs %&gt;% distinct(ID, .keep_all = TRUE) sid_pk_data %&gt;% select(WT, AGE, RACE, SEX) %&gt;% mutate(RACE = as.factor(RACE), SEX = as.factor(SEX)) %&gt;% summary #&gt; WT AGE RACE SEX #&gt; Min. :52.3 Min. :20.0 Asian : 8 Female:28 #&gt; 1st Qu.:58.5 1st Qu.:31.0 Black :12 Male :22 #&gt; Median :64.0 Median :39.5 Caucasian:17 #&gt; Mean :64.1 Mean :38.5 Hispanic :13 #&gt; 3rd Qu.:68.8 3rd Qu.:48.0 #&gt; Max. :80.9 Max. :59.0 Count the number of subjects in each “Race” category # fastest sid_pk_data %&gt;% count(RACE) %&gt;% kable() RACE n Asian 8 Black 12 Caucasian 17 Hispanic 13 # more manual sid_pk_data %&gt;% group_by(RACE) %&gt;% tally # most manual but have more control over column names sid_pk_data %&gt;% group_by(RACE) %&gt;% summarize(num_per_race = n()) %&gt;% kable() calculate the min, mean, and max values for WT, AGE: by Sex sid_pk_data %&gt;% group_by(SEX) %&gt;% summarize( WT_min = min(WT), WT_mean = mean(WT), WT_max = max(WT), AGE_min = min(AGE), AGE_mean = mean(AGE), AGE_max = max(AGE) ) %&gt;% kable() SEX WT_min WT_mean WT_max AGE_min AGE_mean AGE_max Female 52.3 59.5 69.0 20 37.0 51 Male 64.3 70.0 80.9 28 40.5 59 there are also targeted verbs in the form &lt;verb&gt;_at that can specify what columns to act on, and which functions to run sid_pk_data %&gt;% group_by(SEX) %&gt;% summarize_at(vars(WT, AGE), funs(min, mean, max)) %&gt;% kable() SEX WT_min AGE_min WT_mean AGE_mean WT_max AGE_max Female 52.3 20 59.5 37.0 69.0 51 Male 64.3 28 70.0 40.5 80.9 59 What is the Average numbers samples(observations) per individual in this dataset. Hint: make sure you are only counting samples, rows with AMT values are not considered observations. # observations are those with NA AMT values pk_data_cobs %&gt;% filter(is.na(AMT)) %&gt;% group_by(ID) %&gt;% summarize(num_obs = n()) %&gt;% # ungroup so no longer calculating by grouping variable ID ungroup %&gt;% summarize(average_obs = mean(num_obs)) %&gt;% kable() 2.4 average_obs 22 Calculate the Mean, 5th, and 95th percentile concentration at each time point for each formulation and dose level. hint: you can use ?quantile to calculate various quantiles pk_data_cobs %&gt;% mutate(COBS = as.numeric(COBS)) %&gt;% filter(!is.na(COBS)) %&gt;% group_by(TIME, FORM, DOSE) %&gt;% summarize(q05 = quantile(COBS, 0.05), q50 = quantile(COBS, 0.5), q95 = quantile(COBS, 0.95)) %&gt;% arrange(FORM, DOSE, TIME) %&gt;% head %&gt;% kable() TIME FORM DOSE q05 q50 q95 0.25 IV 100 823 1716 2751 0.50 IV 100 1000 1537 2815 1.00 IV 100 1071 1423 2629 2.00 IV 100 750 1216 1980 3.00 IV 100 789 1059 1803 4.00 IV 100 561 909 1278 devtools::session_info() #&gt; Session info ------------------------------------------------------------- #&gt; setting value #&gt; version R version 3.4.0 (2017-04-21) #&gt; system x86_64, mingw32 #&gt; ui RTerm #&gt; language (EN) #&gt; collate English_United States.1252 #&gt; tz Europe/Prague #&gt; date 2017-06-05 #&gt; Packages ----------------------------------------------------------------- #&gt; package * version date source #&gt; assertthat 0.2.0 2017-04-11 CRAN (R 3.4.0) #&gt; backports 1.1.0 2017-05-22 CRAN (R 3.4.0) #&gt; base * 3.4.0 2017-04-21 local #&gt; bindr 0.1 2016-11-13 CRAN (R 3.4.0) #&gt; bindrcpp * 0.1 2016-12-11 CRAN (R 3.4.0) #&gt; bookdown 0.4 2017-05-20 CRAN (R 3.4.0) #&gt; broom 0.4.2 2017-02-13 CRAN (R 3.4.0) #&gt; cellranger 1.1.0 2016-07-27 CRAN (R 3.4.0) #&gt; codetools 0.2-15 2016-10-05 CRAN (R 3.4.0) #&gt; colorspace 1.3-2 2016-12-14 CRAN (R 3.4.0) #&gt; compiler 3.4.0 2017-04-21 local #&gt; datasets * 3.4.0 2017-04-21 local #&gt; devtools 1.13.1 2017-05-13 CRAN (R 3.4.0) #&gt; digest 0.6.12 2017-01-27 CRAN (R 3.4.0) #&gt; dplyr * 0.6.0 2017-06-02 Github (tidyverse/dplyr@b064c4b) #&gt; evaluate 0.10 2016-10-11 CRAN (R 3.4.0) #&gt; forcats 0.2.0 2017-01-23 CRAN (R 3.4.0) #&gt; foreign 0.8-67 2016-09-13 CRAN (R 3.4.0) #&gt; ggplot2 * 2.2.1 2016-12-30 CRAN (R 3.4.0) #&gt; glue 1.0.0 2017-04-17 CRAN (R 3.4.0) #&gt; graphics * 3.4.0 2017-04-21 local #&gt; grDevices * 3.4.0 2017-04-21 local #&gt; grid 3.4.0 2017-04-21 local #&gt; gtable 0.2.0 2016-02-26 CRAN (R 3.4.0) #&gt; haven 1.0.0 2016-09-23 CRAN (R 3.4.0) #&gt; highr 0.6 2016-05-09 CRAN (R 3.4.0) #&gt; hms 0.3 2016-11-22 CRAN (R 3.4.0) #&gt; htmltools 0.3.6 2017-04-28 CRAN (R 3.4.0) #&gt; httr 1.2.1 2016-07-03 CRAN (R 3.4.0) #&gt; jsonlite 1.5 2017-06-01 CRAN (R 3.4.0) #&gt; knitr * 1.16 2017-05-18 CRAN (R 3.4.0) #&gt; lattice 0.20-35 2017-03-25 CRAN (R 3.4.0) #&gt; lazyeval 0.2.0 2016-06-12 CRAN (R 3.4.0) #&gt; lubridate 1.6.0 2016-09-13 CRAN (R 3.4.0) #&gt; magrittr 1.5 2014-11-22 CRAN (R 3.4.0) #&gt; memoise 1.1.0 2017-04-21 CRAN (R 3.4.0) #&gt; methods 3.4.0 2017-04-21 local #&gt; mnormt 1.5-5 2016-10-15 CRAN (R 3.4.0) #&gt; modelr 0.1.0 2016-08-31 CRAN (R 3.4.0) #&gt; munsell 0.4.3 2016-02-13 CRAN (R 3.4.0) #&gt; nlme 3.1-131 2017-02-06 CRAN (R 3.4.0) #&gt; parallel 3.4.0 2017-04-21 local #&gt; PKPDmisc * 1.0.0 2017-06-02 Github (dpastoor/PKPDmisc@23e1f49) #&gt; plyr 1.8.4 2016-06-08 CRAN (R 3.4.0) #&gt; psych 1.7.5 2017-05-03 CRAN (R 3.4.0) #&gt; purrr * 0.2.2.2 2017-05-11 CRAN (R 3.4.0) #&gt; R6 2.2.1 2017-05-10 CRAN (R 3.4.0) #&gt; Rcpp 0.12.11 2017-05-22 CRAN (R 3.4.0) #&gt; readr * 1.1.1 2017-05-16 CRAN (R 3.4.0) #&gt; readxl 1.0.0 2017-04-18 CRAN (R 3.4.0) #&gt; reshape2 1.4.2 2016-10-22 CRAN (R 3.4.0) #&gt; rlang 0.1.1 2017-05-18 CRAN (R 3.4.0) #&gt; rmarkdown 1.5.9000 2017-06-03 Github (rstudio/rmarkdown@ea515ef) #&gt; rprojroot 1.2 2017-01-16 CRAN (R 3.4.0) #&gt; rvest 0.3.2 2016-06-17 CRAN (R 3.4.0) #&gt; scales 0.4.1 2016-11-09 CRAN (R 3.4.0) #&gt; stats * 3.4.0 2017-04-21 local #&gt; stringi 1.1.5 2017-04-07 CRAN (R 3.4.0) #&gt; stringr 1.2.0 2017-02-18 CRAN (R 3.4.0) #&gt; tibble * 1.3.3 2017-05-28 CRAN (R 3.4.0) #&gt; tidyr * 0.6.3 2017-05-15 CRAN (R 3.4.0) #&gt; tidyverse * 1.1.1 2017-01-27 CRAN (R 3.4.0) #&gt; tools 3.4.0 2017-04-21 local #&gt; utils * 3.4.0 2017-04-21 local #&gt; withr 1.0.2 2016-06-20 CRAN (R 3.4.0) #&gt; xml2 1.1.1 2017-01-24 CRAN (R 3.4.0) #&gt; yaml 2.1.14 2016-11-12 CRAN (R 3.4.0) "],
["advanced-ggplot-customizations.html", "3 advanced ggplot customizations", " 3 advanced ggplot customizations Help! Your colleague Jon has come to you for help. He is just starting to use ggplot and is having trouble. Thankfully, he has gotten started on making the necessary plots, and has a good idea what he wants. Your job, should you choose to accept it, is to help finish off the plots Jon has started. Jon has been kind enough to provide you with a zipped R project. You can unzip the project and click on the .Rproj to open up the project to get you started. library(tidyverse, warn.conflicts = FALSE) #&gt; Loading tidyverse: ggplot2 #&gt; Loading tidyverse: tibble #&gt; Loading tidyverse: tidyr #&gt; Loading tidyverse: readr #&gt; Loading tidyverse: purrr #&gt; Loading tidyverse: dplyr #&gt; Conflicts with tidy packages ---------------------------------------------- #&gt; filter(): dplyr, stats #&gt; lag(): dplyr, stats library(knitr) library(PKPDdatasets) library(PKPDmisc) opts_chunk$set(cache=T, fig.width=9) The data Jon is working with conventiently comes from the dapa_iv_oral dataset in the PKPDdatasets package. Jon’s first attempt to make a concentration time plot for each ID looks funny. oral_data &lt;- dapa_IV_oral %&gt;% filter(FORMULATION == &quot;ORAL&quot;) kable(head(oral_data)) ID TIME TAD COBS AMT_IV AMT_ORAL OCC AGE WEIGHT GENDER FORMULATION 1 168 0.00 0.0 0 5000 2 44 70.5 0 ORAL 1 168 0.05 13.7 0 0 2 44 70.5 0 ORAL 1 168 0.35 62.3 0 0 2 44 70.5 0 ORAL 1 168 0.50 67.9 0 0 2 44 70.5 0 ORAL 1 169 0.75 66.3 0 0 2 44 70.5 0 ORAL 1 169 1.00 86.3 0 0 2 44 70.5 0 ORAL ggplot(oral_data, aes(x = TAD, y = COBS, group = ID, color = OCC)) + geom_line() + facet_wrap(~ID) You will need to help him adjust: fix lines (hint - check out interaction) fix line color to be discrete rename axes change legend name adjust scale adjust axis labels and numbers for text color and size adjust the output width so the x-axis numbers don’t overlap 3.0.1 to get a final plot that looks like this: ggplot(oral_data, aes(x = TAD, y = COBS, group = interaction(ID, OCC), color = factor(OCC))) + geom_line(size = 1.05) + facet_wrap(~ID) + base_theme() + xlab(&quot;Time After Dose, hours&quot;) + ylab(&quot;Concentration, ug/mL&quot;) + scale_color_discrete(name=&quot;Occasion&quot;) + scale_y_log10() #&gt; Warning: Transformation introduced infinite values in continuous y-axis Jon now wants to get a general feel for the covariate weight, and thus wants to color by weight. ggplot(oral_data, aes(x = TAD, y = COBS, group = ID)) + geom_line(size = 1.05) + facet_wrap(~OCC) + base_theme() + xlab(&quot;Time After Dose, hours&quot;) + ylab(&quot;Concentration, ug/mL&quot;) + scale_y_log10() #&gt; Warning: Transformation introduced infinite values in continuous y-axis He needs your help fixing the facet strips to be better labeled add the color to weight getting the plots to be row-wise rather than side-by-side 3.0.2 so it will look like this: occ_labels &lt;- c( &#39;1&#39; = &quot;5 mg IV&quot;, &#39;2&#39;= &quot;5 mg&quot;, &#39;3&#39; = &quot;10 mg&quot;, &#39;4&#39; = &quot;25 mg&quot; ) ct_colWT &lt;- ggplot(oral_data, aes(x = TAD, y = COBS, group = interaction(ID, OCC), color = WEIGHT)) + geom_line(size = 1.05) + base_theme() + xlab(&quot;Time After Dose, hours&quot;) + ylab(&quot;Concentration, ug/mL&quot;) + scale_y_log10() ct_colWT + facet_grid(OCC~., labeller=labeller(OCC = occ_labels)) + theme(strip.text = element_text(size = 16, color=&quot;black&quot;)) #&gt; Warning: Transformation introduced infinite values in continuous y-axis But just in case also wants to see the old side-by-side view as well. He needs your help change facetting move legend to be below the plot 3.0.3 so it looks like this: ct_colWT + facet_grid(OCC~., labeller=labeller(OCC = occ_labels)) + theme(strip.text = element_text(size = 16, color=&quot;black&quot;)) + theme(legend.position=&quot;bottom&quot;) #&gt; Warning: Transformation introduced infinite values in continuous y-axis Jon decided to look at the 5 mg dose. He needs help figuring out how to add mean lines. He wants to show that the general trend for males and females is similar and so would like to overlay the geometric mean profile for males and females on the concentration-time plot below. oral_data_occ2 &lt;- oral_data %&gt;% filter(OCC==2) # calculate geometric mean here He did a couple calculations by hand so you can check that the values are the same. mean_occ2 &lt;- oral_data %&gt;% filter(OCC==2) %&gt;% group_by(GENDER, TAD) %&gt;% summarize(meanCONC = round(exp(mean(log(COBS))),3)) head(mean_occ2, n = 3) #&gt; # A tibble: 3 x 3 #&gt; # Groups: GENDER [1] #&gt; GENDER TAD meanCONC #&gt; &lt;fctr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 0 0.00 0.0 #&gt; 2 0 0.05 11.0 #&gt; 3 0 0.35 47.6 tail(mean_occ2, n = 3) #&gt; # A tibble: 3 x 3 #&gt; # Groups: GENDER [1] #&gt; GENDER TAD meanCONC #&gt; &lt;fctr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 16 1.409 #&gt; 2 1 20 1.081 #&gt; 3 1 24 0.833 He’s gotten started on the plot but can’t figure out how to overlay the profiles. ggplot(oral_data_occ2, aes(x = TAD, y = COBS, group = ID)) + geom_line(size = 1.05)+ base_theme() + xlab(&quot;Time After Dose, hours&quot;) + ylab(&quot;Concentration, ug/mL&quot;) + scale_y_log10() #&gt; Warning: Transformation introduced infinite values in continuous y-axis To get the final result he asks you to: calculate the geometric mean values for males and females overlay the results and color by Gender update the legend with the name ‘Gender’ and Male/Female Labels move the legend to be in the top right corner inside the plot add another break in the y axis for 50 3.0.4 So it looks like this: ggplot(oral_data_occ2, aes(x = TAD, y = COBS, group = ID)) + geom_line(size = 1.05)+ base_theme() + xlab(&quot;Time After Dose, hours&quot;) + ylab(&quot;Concentration, ug/mL&quot;) + scale_color_discrete(name=&quot;Gender&quot;, labels= c(&quot;Male&quot;, &quot;Female&quot;)) + scale_y_log10(breaks = c(1, 10 , 50, 100)) + geom_line(data = mean_occ2, aes(x = TAD, y = meanCONC, group = GENDER, color = GENDER ), size = 1.5)+ theme(legend.justification=c(1,1), legend.position=c(1,1)) #&gt; Warning: Transformation introduced infinite values in continuous y-axis #&gt; Warning: Transformation introduced infinite values in continuous y-axis devtools::session_info() #&gt; Session info ------------------------------------------------------------- #&gt; setting value #&gt; version R version 3.4.0 (2017-04-21) #&gt; system x86_64, mingw32 #&gt; ui RTerm #&gt; language (EN) #&gt; collate English_United States.1252 #&gt; tz Europe/Prague #&gt; date 2017-06-05 #&gt; Packages ----------------------------------------------------------------- #&gt; package * version date source #&gt; assertthat 0.2.0 2017-04-11 CRAN (R 3.4.0) #&gt; backports 1.1.0 2017-05-22 CRAN (R 3.4.0) #&gt; base * 3.4.0 2017-04-21 local #&gt; bindr 0.1 2016-11-13 CRAN (R 3.4.0) #&gt; bindrcpp * 0.1 2016-12-11 CRAN (R 3.4.0) #&gt; bookdown 0.4 2017-05-20 CRAN (R 3.4.0) #&gt; broom 0.4.2 2017-02-13 CRAN (R 3.4.0) #&gt; cellranger 1.1.0 2016-07-27 CRAN (R 3.4.0) #&gt; codetools 0.2-15 2016-10-05 CRAN (R 3.4.0) #&gt; colorspace 1.3-2 2016-12-14 CRAN (R 3.4.0) #&gt; compiler 3.4.0 2017-04-21 local #&gt; datasets * 3.4.0 2017-04-21 local #&gt; devtools 1.13.1 2017-05-13 CRAN (R 3.4.0) #&gt; digest 0.6.12 2017-01-27 CRAN (R 3.4.0) #&gt; dplyr * 0.6.0 2017-06-02 Github (tidyverse/dplyr@b064c4b) #&gt; evaluate 0.10 2016-10-11 CRAN (R 3.4.0) #&gt; forcats 0.2.0 2017-01-23 CRAN (R 3.4.0) #&gt; foreign 0.8-67 2016-09-13 CRAN (R 3.4.0) #&gt; ggplot2 * 2.2.1 2016-12-30 CRAN (R 3.4.0) #&gt; glue 1.0.0 2017-04-17 CRAN (R 3.4.0) #&gt; graphics * 3.4.0 2017-04-21 local #&gt; grDevices * 3.4.0 2017-04-21 local #&gt; grid 3.4.0 2017-04-21 local #&gt; gtable 0.2.0 2016-02-26 CRAN (R 3.4.0) #&gt; haven 1.0.0 2016-09-23 CRAN (R 3.4.0) #&gt; highr 0.6 2016-05-09 CRAN (R 3.4.0) #&gt; hms 0.3 2016-11-22 CRAN (R 3.4.0) #&gt; htmltools 0.3.6 2017-04-28 CRAN (R 3.4.0) #&gt; httr 1.2.1 2016-07-03 CRAN (R 3.4.0) #&gt; jsonlite 1.5 2017-06-01 CRAN (R 3.4.0) #&gt; knitr * 1.16 2017-05-18 CRAN (R 3.4.0) #&gt; labeling 0.3 2014-08-23 CRAN (R 3.4.0) #&gt; lattice 0.20-35 2017-03-25 CRAN (R 3.4.0) #&gt; lazyeval 0.2.0 2016-06-12 CRAN (R 3.4.0) #&gt; lubridate 1.6.0 2016-09-13 CRAN (R 3.4.0) #&gt; magrittr 1.5 2014-11-22 CRAN (R 3.4.0) #&gt; memoise 1.1.0 2017-04-21 CRAN (R 3.4.0) #&gt; methods 3.4.0 2017-04-21 local #&gt; mnormt 1.5-5 2016-10-15 CRAN (R 3.4.0) #&gt; modelr 0.1.0 2016-08-31 CRAN (R 3.4.0) #&gt; munsell 0.4.3 2016-02-13 CRAN (R 3.4.0) #&gt; nlme 3.1-131 2017-02-06 CRAN (R 3.4.0) #&gt; parallel 3.4.0 2017-04-21 local #&gt; PKPDdatasets * 0.1.0 2017-06-02 Github (dpastoor/PKPDdatasets@9eaa831) #&gt; PKPDmisc * 1.0.0 2017-06-02 Github (dpastoor/PKPDmisc@23e1f49) #&gt; plyr 1.8.4 2016-06-08 CRAN (R 3.4.0) #&gt; psych 1.7.5 2017-05-03 CRAN (R 3.4.0) #&gt; purrr * 0.2.2.2 2017-05-11 CRAN (R 3.4.0) #&gt; R6 2.2.1 2017-05-10 CRAN (R 3.4.0) #&gt; Rcpp 0.12.11 2017-05-22 CRAN (R 3.4.0) #&gt; readr * 1.1.1 2017-05-16 CRAN (R 3.4.0) #&gt; readxl 1.0.0 2017-04-18 CRAN (R 3.4.0) #&gt; reshape2 1.4.2 2016-10-22 CRAN (R 3.4.0) #&gt; rlang 0.1.1 2017-05-18 CRAN (R 3.4.0) #&gt; rmarkdown 1.5.9000 2017-06-03 Github (rstudio/rmarkdown@ea515ef) #&gt; rprojroot 1.2 2017-01-16 CRAN (R 3.4.0) #&gt; rvest 0.3.2 2016-06-17 CRAN (R 3.4.0) #&gt; scales 0.4.1 2016-11-09 CRAN (R 3.4.0) #&gt; stats * 3.4.0 2017-04-21 local #&gt; stringi 1.1.5 2017-04-07 CRAN (R 3.4.0) #&gt; stringr 1.2.0 2017-02-18 CRAN (R 3.4.0) #&gt; tibble * 1.3.3 2017-05-28 CRAN (R 3.4.0) #&gt; tidyr * 0.6.3 2017-05-15 CRAN (R 3.4.0) #&gt; tidyverse * 1.1.1 2017-01-27 CRAN (R 3.4.0) #&gt; tools 3.4.0 2017-04-21 local #&gt; utils * 3.4.0 2017-04-21 local #&gt; withr 1.0.2 2016-06-20 CRAN (R 3.4.0) #&gt; xml2 1.1.1 2017-01-24 CRAN (R 3.4.0) #&gt; yaml 2.1.14 2016-11-12 CRAN (R 3.4.0) "],
["tidying-data.html", "4 Tidying Data 4.1 data checkout for all covariates", " 4 Tidying Data library(knitr) library(tidyverse) #&gt; Loading tidyverse: ggplot2 #&gt; Loading tidyverse: tibble #&gt; Loading tidyverse: tidyr #&gt; Loading tidyverse: readr #&gt; Loading tidyverse: purrr #&gt; Loading tidyverse: dplyr #&gt; Conflicts with tidy packages ---------------------------------------------- #&gt; filter(): dplyr, stats #&gt; lag(): dplyr, stats library(PKPDmisc) ebe_cov &lt;- read_csv(&quot;../data/ebe_cov.csv&quot;) #&gt; Parsed with column specification: #&gt; cols( #&gt; ID = col_integer(), #&gt; ETA1 = col_double(), #&gt; ETA2 = col_double(), #&gt; ETA3 = col_integer(), #&gt; ETA4 = col_double(), #&gt; ETA5 = col_double(), #&gt; ETA6 = col_double(), #&gt; ETA7 = col_double(), #&gt; ETA8 = col_double(), #&gt; ETA9 = col_double(), #&gt; BW = col_double(), #&gt; BMI = col_double(), #&gt; AGE = col_integer(), #&gt; AST = col_integer(), #&gt; ALT = col_integer(), #&gt; CRCL = col_double(), #&gt; SEX = col_integer(), #&gt; RACE = col_integer() #&gt; ) Remove all the columns with ETAS and name dataframe covs covs &lt;- ebe_cov %&gt;% select(-contains(&quot;ETA&quot;)) Find all columns with an NA value, and the associated ID has_missing &lt;- covs %&gt;% group_by(ID) %&gt;% select_if(~any(is.na(.))) %&gt;% ungroup() head(has_missing) #&gt; # A tibble: 6 x 3 #&gt; ID BW SEX #&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 1 109.4 1 #&gt; 2 4 120.2 0 #&gt; 3 5 83.0 0 #&gt; 4 6 64.2 0 #&gt; 5 7 74.4 0 #&gt; 6 8 68.4 0 missing_ids &lt;- has_missing %&gt;% gather(cov, values, -ID) %&gt;% filter(is.na(values)) missing_ids #&gt; # A tibble: 2 x 3 #&gt; ID cov values #&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 69 BW NA #&gt; 2 65 SEX NA Impute the NA values using the mean for any continous variable, and largest group for categorical has_missing %&gt;% select(-ID) %&gt;% mutate(SEX = as.factor(SEX)) %&gt;% summary #&gt; BW SEX #&gt; Min. : 51.7 0 :48 #&gt; 1st Qu.: 75.2 1 :12 #&gt; Median : 88.1 NA&#39;s: 1 #&gt; Mean : 90.3 #&gt; 3rd Qu.:103.6 #&gt; Max. :159.2 #&gt; NA&#39;s :1 replacement_values &lt;- has_missing %&gt;% summarize(BW = mean(BW, na.rm = T)) %&gt;% mutate(SEX = 0) covs &lt;- covs %&gt;% replace_na(replace = as.list(replacement_values)) covs %&gt;% filter(ID %in% missing_ids$ID) #&gt; # A tibble: 2 x 9 #&gt; ID BW BMI AGE AST ALT CRCL SEX RACE #&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 65 97.5 32.7 47 18 23 116 0 0 #&gt; 2 69 90.3 27.5 39 32 53 161 0 1 4.1 data checkout for all covariates Set all categorical covariates to factors with appropriate labels covs_f &lt;- covs %&gt;% mutate(SEXC = factor(SEX, levels = c(0, 1), labels = c(&quot;FEMALE&quot;, &quot;MALE&quot;) ), RACEC = factor(RACE, levels = c(0:2), labels = c(&quot;WHITE&quot;, &quot;BLACK&quot;, &quot;ASIAN&quot;) ) ) %&gt;% select(-SEX, -RACE) g_cont_covs &lt;- covs_f %&gt;% gather(cov, value, BW:CRCL) Plot a scatter plot of all continuous covariates versus ID to check for visual outliers g_cont_covs %&gt;% ggplot(aes(x = ID, y = value)) + geom_point() + facet_wrap(~cov, scales = &quot;free&quot;) Plot a violin/box plot of all continuous covariates versus SEX to check for visual trends g_cont_covs %&gt;% ggplot(aes(x = SEXC, y = value)) + geom_violin() + geom_jitter(width = 0.1) + facet_wrap(~cov, scales = &quot;free&quot;) Plot a violin/box plot of all continuous covariates versus all categorical covariates to check for visual trends g_cont_covs %&gt;% gather(catcov, catvals, RACEC, SEXC) %&gt;% ggplot(aes(x = catvals, y = value)) + geom_violin() + geom_jitter(width = 0.1) + facet_grid(cov~catcov, scales = &quot;free&quot;) #&gt; Warning: attributes are not identical across measure variables; they will #&gt; be dropped devtools::session_info() #&gt; Session info ------------------------------------------------------------- #&gt; setting value #&gt; version R version 3.4.0 (2017-04-21) #&gt; system x86_64, mingw32 #&gt; ui RTerm #&gt; language (EN) #&gt; collate English_United States.1252 #&gt; tz Europe/Prague #&gt; date 2017-06-05 #&gt; Packages ----------------------------------------------------------------- #&gt; package * version date source #&gt; assertthat 0.2.0 2017-04-11 CRAN (R 3.4.0) #&gt; backports 1.1.0 2017-05-22 CRAN (R 3.4.0) #&gt; base * 3.4.0 2017-04-21 local #&gt; bindr 0.1 2016-11-13 CRAN (R 3.4.0) #&gt; bindrcpp * 0.1 2016-12-11 CRAN (R 3.4.0) #&gt; bookdown 0.4 2017-05-20 CRAN (R 3.4.0) #&gt; broom 0.4.2 2017-02-13 CRAN (R 3.4.0) #&gt; cellranger 1.1.0 2016-07-27 CRAN (R 3.4.0) #&gt; codetools 0.2-15 2016-10-05 CRAN (R 3.4.0) #&gt; colorspace 1.3-2 2016-12-14 CRAN (R 3.4.0) #&gt; compiler 3.4.0 2017-04-21 local #&gt; datasets * 3.4.0 2017-04-21 local #&gt; devtools 1.13.1 2017-05-13 CRAN (R 3.4.0) #&gt; digest 0.6.12 2017-01-27 CRAN (R 3.4.0) #&gt; dplyr * 0.6.0 2017-06-02 Github (tidyverse/dplyr@b064c4b) #&gt; evaluate 0.10 2016-10-11 CRAN (R 3.4.0) #&gt; forcats 0.2.0 2017-01-23 CRAN (R 3.4.0) #&gt; foreign 0.8-67 2016-09-13 CRAN (R 3.4.0) #&gt; ggplot2 * 2.2.1 2016-12-30 CRAN (R 3.4.0) #&gt; glue 1.0.0 2017-04-17 CRAN (R 3.4.0) #&gt; graphics * 3.4.0 2017-04-21 local #&gt; grDevices * 3.4.0 2017-04-21 local #&gt; grid 3.4.0 2017-04-21 local #&gt; gtable 0.2.0 2016-02-26 CRAN (R 3.4.0) #&gt; haven 1.0.0 2016-09-23 CRAN (R 3.4.0) #&gt; hms 0.3 2016-11-22 CRAN (R 3.4.0) #&gt; htmltools 0.3.6 2017-04-28 CRAN (R 3.4.0) #&gt; httr 1.2.1 2016-07-03 CRAN (R 3.4.0) #&gt; jsonlite 1.5 2017-06-01 CRAN (R 3.4.0) #&gt; knitr * 1.16 2017-05-18 CRAN (R 3.4.0) #&gt; labeling 0.3 2014-08-23 CRAN (R 3.4.0) #&gt; lattice 0.20-35 2017-03-25 CRAN (R 3.4.0) #&gt; lazyeval 0.2.0 2016-06-12 CRAN (R 3.4.0) #&gt; lubridate 1.6.0 2016-09-13 CRAN (R 3.4.0) #&gt; magrittr 1.5 2014-11-22 CRAN (R 3.4.0) #&gt; memoise 1.1.0 2017-04-21 CRAN (R 3.4.0) #&gt; methods 3.4.0 2017-04-21 local #&gt; mnormt 1.5-5 2016-10-15 CRAN (R 3.4.0) #&gt; modelr 0.1.0 2016-08-31 CRAN (R 3.4.0) #&gt; munsell 0.4.3 2016-02-13 CRAN (R 3.4.0) #&gt; nlme 3.1-131 2017-02-06 CRAN (R 3.4.0) #&gt; parallel 3.4.0 2017-04-21 local #&gt; PKPDmisc * 1.0.0 2017-06-02 Github (dpastoor/PKPDmisc@23e1f49) #&gt; plyr 1.8.4 2016-06-08 CRAN (R 3.4.0) #&gt; psych 1.7.5 2017-05-03 CRAN (R 3.4.0) #&gt; purrr * 0.2.2.2 2017-05-11 CRAN (R 3.4.0) #&gt; R6 2.2.1 2017-05-10 CRAN (R 3.4.0) #&gt; Rcpp 0.12.11 2017-05-22 CRAN (R 3.4.0) #&gt; readr * 1.1.1 2017-05-16 CRAN (R 3.4.0) #&gt; readxl 1.0.0 2017-04-18 CRAN (R 3.4.0) #&gt; reshape2 1.4.2 2016-10-22 CRAN (R 3.4.0) #&gt; rlang 0.1.1 2017-05-18 CRAN (R 3.4.0) #&gt; rmarkdown 1.5.9000 2017-06-03 Github (rstudio/rmarkdown@ea515ef) #&gt; rprojroot 1.2 2017-01-16 CRAN (R 3.4.0) #&gt; rvest 0.3.2 2016-06-17 CRAN (R 3.4.0) #&gt; scales 0.4.1 2016-11-09 CRAN (R 3.4.0) #&gt; stats * 3.4.0 2017-04-21 local #&gt; stringi 1.1.5 2017-04-07 CRAN (R 3.4.0) #&gt; stringr 1.2.0 2017-02-18 CRAN (R 3.4.0) #&gt; tibble * 1.3.3 2017-05-28 CRAN (R 3.4.0) #&gt; tidyr * 0.6.3 2017-05-15 CRAN (R 3.4.0) #&gt; tidyverse * 1.1.1 2017-01-27 CRAN (R 3.4.0) #&gt; tools 3.4.0 2017-04-21 local #&gt; utils * 3.4.0 2017-04-21 local #&gt; withr 1.0.2 2016-06-20 CRAN (R 3.4.0) #&gt; xml2 1.1.1 2017-01-24 CRAN (R 3.4.0) #&gt; yaml 2.1.14 2016-11-12 CRAN (R 3.4.0) "],
["diagnostic-plots.html", "5 Diagnostic Plots", " 5 Diagnostic Plots read in the csv datasets: Residuals library(PKPDmisc) library(knitr) library(tidyverse) #&gt; Loading tidyverse: ggplot2 #&gt; Loading tidyverse: tibble #&gt; Loading tidyverse: tidyr #&gt; Loading tidyverse: readr #&gt; Loading tidyverse: purrr #&gt; Loading tidyverse: dplyr #&gt; Conflicts with tidy packages ---------------------------------------------- #&gt; filter(): dplyr, stats #&gt; lag(): dplyr, stats resid &lt;- read_csv(&quot;../data/Residuals.csv&quot;) #&gt; Parsed with column specification: #&gt; cols( #&gt; Scenario = col_character(), #&gt; ID = col_integer(), #&gt; IVAR = col_double(), #&gt; TAD = col_double(), #&gt; PRED = col_double(), #&gt; IPRED = col_double(), #&gt; DV = col_double(), #&gt; IRES = col_double(), #&gt; Weight = col_double(), #&gt; IWRES = col_double(), #&gt; WRES = col_double(), #&gt; CWRES = col_double(), #&gt; CdfDV = col_integer(), #&gt; TADSeq = col_integer(), #&gt; ObsName = col_character(), #&gt; ResetSeq = col_integer() #&gt; ) Create a Res vs Time function with loess fits for the central tendency and the spread (hint abs() is your friend for the spread). Conditionally allow the loess curve of central tendency to appear, with a default of TRUE. Users should be able to specify the residual column name. gg_res_tad &lt;- function(df, .tad, .res, .show_loess = TRUE) { .tad &lt;- rlang::enexpr(.tad) .res &lt;- rlang::enexpr(.res) ple &lt;- rlang::quo( df %&gt;% ggplot(aes(x = !!.tad, y = !!.res)) + geom_point() + stat_smooth(data = df %&gt;% mutate(!!.res := abs(!!.res)), se = F, color = &quot;blue&quot;) + stat_smooth(data = df %&gt;% mutate(!!.res := -abs(!!.res)), se = F, color = &quot;blue&quot;) + theme_bw() ) output &lt;- rlang::eval_tidy(ple) if (.show_loess) { return( output + stat_smooth(method = &quot;loess&quot;, se=F, color = &quot;red&quot;) ) } return(output) } 5.0.1 CWRES vs time after dose (TAD) gg_res_tad(resid, TAD, CWRES) #&gt; `geom_smooth()` using method = &#39;loess&#39; #&gt; `geom_smooth()` using method = &#39;loess&#39; update your function to flag any point over some threshold as red, with a default of absolute difference of &gt; 2.5 gg_res_tad &lt;- function(df, .tad, .res, .threshold = 2.5, .show_loess = TRUE) { .tad &lt;- rlang::enexpr(.tad) .res &lt;- rlang::enexpr(.res) ple &lt;- rlang::quo( df %&gt;% mutate(HIGHRES__ = ifelse(abs(!!.res) &gt; .threshold, 1, 0)) %&gt;% ggplot(aes(x = !!.tad, y = !!.res)) + geom_point(aes(color = factor(HIGHRES__))) + scale_color_manual(values = c(&quot;black&quot;, &quot;red&quot;), name = &quot;Outlier&quot;, labels = c(&quot;not outlier&quot;, &quot;outlier&quot;)) + stat_smooth(data = df %&gt;% mutate(!!.res := abs(!!.res)), se = F, color = &quot;blue&quot;) + stat_smooth(data = df %&gt;% mutate(!!.res := -abs(!!.res)), se = F, color = &quot;blue&quot;) + theme_bw() ) output &lt;- rlang::eval_tidy(ple) if (.show_loess) { return( output + stat_smooth(method = &quot;loess&quot;, se=F, color = &quot;red&quot;) ) } return(output) } gg_res_tad(resid, TAD, CWRES) #&gt; `geom_smooth()` using method = &#39;loess&#39; #&gt; `geom_smooth()` using method = &#39;loess&#39; devtools::session_info() #&gt; Session info ------------------------------------------------------------- #&gt; setting value #&gt; version R version 3.4.0 (2017-04-21) #&gt; system x86_64, mingw32 #&gt; ui RTerm #&gt; language (EN) #&gt; collate English_United States.1252 #&gt; tz Europe/Prague #&gt; date 2017-06-05 #&gt; Packages ----------------------------------------------------------------- #&gt; package * version date source #&gt; assertthat 0.2.0 2017-04-11 CRAN (R 3.4.0) #&gt; backports 1.1.0 2017-05-22 CRAN (R 3.4.0) #&gt; base * 3.4.0 2017-04-21 local #&gt; bindr 0.1 2016-11-13 CRAN (R 3.4.0) #&gt; bindrcpp * 0.1 2016-12-11 CRAN (R 3.4.0) #&gt; bookdown 0.4 2017-05-20 CRAN (R 3.4.0) #&gt; broom 0.4.2 2017-02-13 CRAN (R 3.4.0) #&gt; cellranger 1.1.0 2016-07-27 CRAN (R 3.4.0) #&gt; codetools 0.2-15 2016-10-05 CRAN (R 3.4.0) #&gt; colorspace 1.3-2 2016-12-14 CRAN (R 3.4.0) #&gt; compiler 3.4.0 2017-04-21 local #&gt; datasets * 3.4.0 2017-04-21 local #&gt; devtools 1.13.1 2017-05-13 CRAN (R 3.4.0) #&gt; digest 0.6.12 2017-01-27 CRAN (R 3.4.0) #&gt; dplyr * 0.6.0 2017-06-02 Github (tidyverse/dplyr@b064c4b) #&gt; evaluate 0.10 2016-10-11 CRAN (R 3.4.0) #&gt; forcats 0.2.0 2017-01-23 CRAN (R 3.4.0) #&gt; foreign 0.8-67 2016-09-13 CRAN (R 3.4.0) #&gt; ggplot2 * 2.2.1 2016-12-30 CRAN (R 3.4.0) #&gt; glue 1.0.0 2017-04-17 CRAN (R 3.4.0) #&gt; graphics * 3.4.0 2017-04-21 local #&gt; grDevices * 3.4.0 2017-04-21 local #&gt; grid 3.4.0 2017-04-21 local #&gt; gtable 0.2.0 2016-02-26 CRAN (R 3.4.0) #&gt; haven 1.0.0 2016-09-23 CRAN (R 3.4.0) #&gt; hms 0.3 2016-11-22 CRAN (R 3.4.0) #&gt; htmltools 0.3.6 2017-04-28 CRAN (R 3.4.0) #&gt; httr 1.2.1 2016-07-03 CRAN (R 3.4.0) #&gt; jsonlite 1.5 2017-06-01 CRAN (R 3.4.0) #&gt; knitr * 1.16 2017-05-18 CRAN (R 3.4.0) #&gt; labeling 0.3 2014-08-23 CRAN (R 3.4.0) #&gt; lattice 0.20-35 2017-03-25 CRAN (R 3.4.0) #&gt; lazyeval 0.2.0 2016-06-12 CRAN (R 3.4.0) #&gt; lubridate 1.6.0 2016-09-13 CRAN (R 3.4.0) #&gt; magrittr 1.5 2014-11-22 CRAN (R 3.4.0) #&gt; memoise 1.1.0 2017-04-21 CRAN (R 3.4.0) #&gt; methods 3.4.0 2017-04-21 local #&gt; mnormt 1.5-5 2016-10-15 CRAN (R 3.4.0) #&gt; modelr 0.1.0 2016-08-31 CRAN (R 3.4.0) #&gt; munsell 0.4.3 2016-02-13 CRAN (R 3.4.0) #&gt; nlme 3.1-131 2017-02-06 CRAN (R 3.4.0) #&gt; parallel 3.4.0 2017-04-21 local #&gt; PKPDmisc * 1.0.0 2017-06-02 Github (dpastoor/PKPDmisc@23e1f49) #&gt; plyr 1.8.4 2016-06-08 CRAN (R 3.4.0) #&gt; psych 1.7.5 2017-05-03 CRAN (R 3.4.0) #&gt; purrr * 0.2.2.2 2017-05-11 CRAN (R 3.4.0) #&gt; R6 2.2.1 2017-05-10 CRAN (R 3.4.0) #&gt; Rcpp 0.12.11 2017-05-22 CRAN (R 3.4.0) #&gt; readr * 1.1.1 2017-05-16 CRAN (R 3.4.0) #&gt; readxl 1.0.0 2017-04-18 CRAN (R 3.4.0) #&gt; reshape2 1.4.2 2016-10-22 CRAN (R 3.4.0) #&gt; rlang 0.1.1 2017-05-18 CRAN (R 3.4.0) #&gt; rmarkdown 1.5.9000 2017-06-03 Github (rstudio/rmarkdown@ea515ef) #&gt; rprojroot 1.2 2017-01-16 CRAN (R 3.4.0) #&gt; rvest 0.3.2 2016-06-17 CRAN (R 3.4.0) #&gt; scales 0.4.1 2016-11-09 CRAN (R 3.4.0) #&gt; stats * 3.4.0 2017-04-21 local #&gt; stringi 1.1.5 2017-04-07 CRAN (R 3.4.0) #&gt; stringr 1.2.0 2017-02-18 CRAN (R 3.4.0) #&gt; tibble * 1.3.3 2017-05-28 CRAN (R 3.4.0) #&gt; tidyr * 0.6.3 2017-05-15 CRAN (R 3.4.0) #&gt; tidyverse * 1.1.1 2017-01-27 CRAN (R 3.4.0) #&gt; tools 3.4.0 2017-04-21 local #&gt; utils * 3.4.0 2017-04-21 local #&gt; withr 1.0.2 2016-06-20 CRAN (R 3.4.0) #&gt; xml2 1.1.1 2017-01-24 CRAN (R 3.4.0) #&gt; yaml 2.1.14 2016-11-12 CRAN (R 3.4.0) "],
["legacy.html", "6 Legacy 6.1 Tidyr legacy 6.2 dplyr data manipulation 6.3 Nonstandard evaluation 6.4 Diagnostic Plots", " 6 Legacy Solutions from previous workshops 6.1 Tidyr legacy library(PKPDmisc) library(knitr) library(lazyeval) library(tidyverse) #&gt; Loading tidyverse: ggplot2 #&gt; Loading tidyverse: tibble #&gt; Loading tidyverse: tidyr #&gt; Loading tidyverse: readr #&gt; Loading tidyverse: purrr #&gt; Loading tidyverse: dplyr #&gt; Conflicts with tidy packages ---------------------------------------------- #&gt; filter(): dplyr, stats #&gt; is_formula(): purrr, lazyeval #&gt; lag(): dplyr, stats eta_cov &lt;- read.csv(&quot;../data/ebe_cov_full.csv&quot;) kable(head(eta_cov)) ID ETA1 ETA2 ETA3 ETA4 ETA5 ETA6 ETA7 ETA8 ETA9 BW BMI AGE AST ALT CRCL SEX RACE ETHNIC 1 0.160 -0.067 0 -0.195 0.058 0.083 0.167 0.204 -0.114 109.4 38.3 48 13 17 131 1 1 0 4 0.681 0.165 0 0.276 -0.107 0.099 -1.562 0.355 0.056 120.2 31.3 53 38 77 177 0 1 0 5 0.480 0.017 0 -0.302 0.062 -0.287 0.260 -0.152 0.022 83.0 24.5 32 26 35 111 0 1 0 6 0.339 0.001 0 -0.105 0.079 -0.228 -0.326 -0.138 0.105 64.2 21.0 33 19 20 97 0 1 0 7 -0.139 0.187 0 0.155 0.260 0.122 -1.381 0.220 -0.063 74.4 26.1 47 16 25 93 0 1 0 8 -0.115 0.060 0 -0.063 0.230 -0.328 0.317 -0.492 0.076 68.4 21.8 32 15 24 103 0 1 0 g_eta_cov &lt;- eta_cov %&gt;% gather(cov_name, cov_value, BW:CRCL) kable(head(g_eta_cov)) ID ETA1 ETA2 ETA3 ETA4 ETA5 ETA6 ETA7 ETA8 ETA9 SEX RACE ETHNIC cov_name cov_value 1 0.160 -0.067 0 -0.195 0.058 0.083 0.167 0.204 -0.114 1 1 0 BW 109.4 4 0.681 0.165 0 0.276 -0.107 0.099 -1.562 0.355 0.056 0 1 0 BW 120.2 5 0.480 0.017 0 -0.302 0.062 -0.287 0.260 -0.152 0.022 0 1 0 BW 83.0 6 0.339 0.001 0 -0.105 0.079 -0.228 -0.326 -0.138 0.105 0 1 0 BW 64.2 7 -0.139 0.187 0 0.155 0.260 0.122 -1.381 0.220 -0.063 0 1 0 BW 74.4 8 -0.115 0.060 0 -0.063 0.230 -0.328 0.317 -0.492 0.076 0 1 0 BW 68.4 lazily evaluated function for ggplot plots eta_cov_scatter &lt;- function(df, xval = &quot;cov_value&quot;, yval, cov_name = &quot;cov_name&quot;) { lazy_plot &lt;- lazyeval::interp(~ggplot(df, aes(x = cov_value, y = ETA1)) + geom_point() + facet_wrap(~cov_name, scales=&quot;free&quot;), cov_value = as.name(xval), ETA1 = as.name(yval), cov_name = as.name(cov_name)) return(lazyeval::lazy_eval(lazy_plot)) } 6.1.1 Single plot example eta_cov_scatter(g_eta_cov, yval = &quot;ETA1&quot;) 6.1.2 Iterate through multiple ETA values lapply(paste0(&quot;ETA&quot;, 1:4), function(eta, g_eta_cov) { eta_cov_scatter(g_eta_cov, yval = eta) }, g_eta_cov) #&gt; [[1]] #&gt; #&gt; [[2]] #&gt; #&gt; [[3]] #&gt; #&gt; [[4]] 6.1.3 Double stack We can actually gather again g2_eta_cov &lt;- g_eta_cov %&gt;% gather(eta_name, eta_value, ETA1:ETA9 ) kable(head(g2_eta_cov)) ID SEX RACE ETHNIC cov_name cov_value eta_name eta_value 1 1 1 0 BW 109.4 ETA1 0.160 4 0 1 0 BW 120.2 ETA1 0.681 5 0 1 0 BW 83.0 ETA1 0.480 6 0 1 0 BW 64.2 ETA1 0.339 7 0 1 0 BW 74.4 ETA1 -0.139 8 0 1 0 BW 68.4 ETA1 -0.115 kable(tail(g2_eta_cov)) ID SEX RACE ETHNIC cov_name cov_value eta_name eta_value 3289 91 0 1 0 CRCL 161 ETA9 0.008 3290 92 0 1 0 CRCL 124 ETA9 0.052 3291 93 1 1 0 CRCL 136 ETA9 0.134 3292 95 0 1 0 CRCL 213 ETA9 0.073 3293 97 0 1 0 CRCL 127 ETA9 -0.007 3294 98 0 1 1 CRCL 86 ETA9 0.026 Then we can split up the plots split_eta_cov &lt;- g2_eta_cov %&gt;% split(.$cov_name) 6.1.4 plot all releationships lapply(split_eta_cov, function(x) { cov_name &lt;- unique(x$cov_name) ggplot(x, aes(x = cov_value, y = eta_value)) + geom_point() + facet_wrap(~eta_name, scales = &quot;free&quot;) + geom_smooth(se = F) + ggtitle(cov_name) + xlab(cov_name) }) #&gt; $AGE #&gt; `geom_smooth()` using method = &#39;loess&#39; #&gt; #&gt; $ALT #&gt; `geom_smooth()` using method = &#39;loess&#39; #&gt; #&gt; $AST #&gt; `geom_smooth()` using method = &#39;loess&#39; #&gt; #&gt; $BMI #&gt; `geom_smooth()` using method = &#39;loess&#39; #&gt; #&gt; $BW #&gt; `geom_smooth()` using method = &#39;loess&#39; #&gt; #&gt; $CRCL #&gt; `geom_smooth()` using method = &#39;loess&#39; 6.2 dplyr data manipulation library(PKPDmisc) library(knitr) library(tidyverse) Objectives: Import datasets and documents Perform basic data manipulation upon importing the data. 6.2.1 Task-I Use the .csv files demog, IV, and Oral provided into the data object folder. Read in all three csv files and give them descriptive names (not data1, data2, data3) demog &lt;- read_csv(&quot;../data/demog.csv&quot;) #&gt; Parsed with column specification: #&gt; cols( #&gt; ID = col_integer(), #&gt; SEX = col_character(), #&gt; WT = col_double(), #&gt; AGE = col_integer(), #&gt; RACE = col_character() #&gt; ) iv_data &lt;- read_csv(&quot;../data/IV.csv&quot;) #&gt; Parsed with column specification: #&gt; cols( #&gt; ID = col_integer(), #&gt; TIME = col_double(), #&gt; DV = col_character(), #&gt; AMT = col_integer(), #&gt; DOSE = col_integer() #&gt; ) oral_data &lt;- read_csv(&quot;../data/ORAL.csv&quot;) #&gt; Parsed with column specification: #&gt; cols( #&gt; ID = col_integer(), #&gt; TIME = col_double(), #&gt; DV = col_character(), #&gt; AMT = col_integer(), #&gt; DOSE = col_integer() #&gt; ) The goals of this section: Use data manipulation tools to prepare the dataset for analysis 6.2.2 Task-II Rename “DV” column as “COBS” iv_data &lt;- iv_data %&gt;% rename(COBS = DV) oral_data &lt;- oral_data %&gt;% rename(COBS = DV) Add a Formulation column and label IV/Oral for each dataset iv_data &lt;- iv_data %&gt;% mutate(FORM = &quot;IV&quot;) oral_data &lt;- oral_data %&gt;% mutate(FORM = &quot;ORAL&quot;) Appropriately merge the demographics dataset into the IV and Oral dataset Create one integrated dataset with both IV and Oral data. combined_data &lt;- bind_rows(iv_data, oral_data) ## check to see if any ids not in the other anti_join(combined_data, demog) #&gt; Joining, by = &quot;ID&quot; #&gt; # A tibble: 0 x 6 #&gt; # ... with 6 variables: ID &lt;int&gt;, TIME &lt;dbl&gt;, COBS &lt;chr&gt;, AMT &lt;int&gt;, #&gt; # DOSE &lt;int&gt;, FORM &lt;chr&gt; anti_join(demog, combined_data) #&gt; Joining, by = &quot;ID&quot; #&gt; # A tibble: 2 x 5 #&gt; ID SEX WT AGE RACE #&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 51 Male 60 28 Caucasian #&gt; 2 52 Female 70 33 Asian Two individuals do not have any concentration-time data all_data &lt;- left_join(combined_data, demog) #&gt; Joining, by = &quot;ID&quot; Perform the following tasks: Ensure that the following columns are numeric and not text: TIME, COBS, WT, AGE, AMT and DOSEs all_data %&gt;% select(TIME, COBS, WT, AGE, AMT, DOSE) %&gt;% str #&gt; Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 1200 obs. of 6 variables: #&gt; $ TIME: num 0 0.25 0.5 1 2 3 4 6 8 12 ... #&gt; $ COBS: chr NA &quot;1273.5&quot; &quot;995.38&quot; &quot;1254.7&quot; ... #&gt; $ WT : num 56.8 56.8 56.8 56.8 56.8 56.8 56.8 56.8 56.8 56.8 ... #&gt; $ AGE : int 28 28 28 28 28 28 28 28 28 28 ... #&gt; $ AMT : int 100 NA NA NA NA NA NA NA NA NA ... #&gt; $ DOSE: int 100 100 100 100 100 100 100 100 100 100 ... COBS is a character column, therefore want to find out what character values exist # check what character values are present unique_non_numerics(all_data$COBS) #&gt; [1] &quot;BQL&quot; b. Change the following: c. Create a new column called BQLFLAG which takes a value of &quot;0&quot; if there is a numerical value in CObs and &quot;1&quot; if there is &quot;BQL&quot; in CObs. # if don&#39;t manually specify to handle NA COBS, will also get NA values for BQLFLAG all_data &lt;- all_data %&gt;% mutate(BQLFLAG = ifelse(is.na(COBS), 0, ifelse(COBS == &quot;BQL&quot;, 1, 0)), COBS = as_numeric(COBS)) #&gt; Warning in as_numeric(COBS): NAs introduced by coercion all_data %&gt;% head %&gt;% kable ID TIME COBS AMT DOSE FORM SEX WT AGE RACE BQLFLAG 1 0.00 NA 100 100 IV Female 56.8 28 Hispanic 0 1 0.25 1274 NA 100 IV Female 56.8 28 Hispanic 0 1 0.50 995 NA 100 IV Female 56.8 28 Hispanic 0 1 1.00 1255 NA 100 IV Female 56.8 28 Hispanic 0 1 2.00 1038 NA 100 IV Female 56.8 28 Hispanic 0 1 3.00 1135 NA 100 IV Female 56.8 28 Hispanic 0 all_data %&gt;% filter(BQLFLAG ==1) %&gt;% kable ID TIME COBS AMT DOSE FORM SEX WT AGE RACE BQLFLAG 20 24 NA NA 100 IV Male 80.9 31 Asian 1 20 24 NA NA 100 ORAL Male 80.9 31 Asian 1 d. Filter the dataset such that you remove all rows where BQLFLAG=1 i. WT from lb to kg iv. CObs from μg/mL to μg/L f_all_data &lt;- all_data %&gt;% filter(BQLFLAG != 1) f_all_data_adjunits &lt;- f_all_data %&gt;% mutate(WT = WT/2.2, COBS = COBS*1000) f_all_data_adjunits %&gt;% head %&gt;% kable ID TIME COBS AMT DOSE FORM SEX WT AGE RACE BQLFLAG 1 0.00 NA 100 100 IV Female 25.8 28 Hispanic 0 1 0.25 1273500 NA 100 IV Female 25.8 28 Hispanic 0 1 0.50 995380 NA 100 IV Female 25.8 28 Hispanic 0 1 1.00 1254700 NA 100 IV Female 25.8 28 Hispanic 0 1 2.00 1037600 NA 100 IV Female 25.8 28 Hispanic 0 1 3.00 1135400 NA 100 IV Female 25.8 28 Hispanic 0 e. Create a new column called &quot;GENDER&quot; where: i. Female = 0 ii. Male = 1 f. Create a new column called RACEN where: i. Caucasian = 0 ii. Asian = 1 iii. Black = 2 iv. Hispanic = 3 g. Create a new column called &quot;LOGCOBS&quot; where CObs is in the log scale h. Create a new column called &quot;USUBJID&quot; - unique subject ID as combination of formulation and ID (hint check out `?interaction`) i. Remove the following columns i. SEX ii. RACE final_data &lt;- f_all_data_adjunits %&gt;% mutate( GENDER = ifelse(SEX == &quot;Female&quot;, 0, 1), RACEN = as.numeric(factor(RACE, levels = c(&quot;Caucasian&quot;, &quot;Asian&quot;, &quot;Black&quot;, &quot;Hispanic&quot;))), LOGCOBS = log(COBS), USUBJID = interaction(ID, FORM) ) %&gt;% select(-SEX, -RACE) Save the above modifications as a new csv file write_csv(final_data, &quot;iv_oral_alldat.csv&quot;, na = &quot;.&quot;) 6.2.3 Summary Statistics show a summary for all demographic columns final_data &lt;- final_data %&gt;% mutate(GENDER = as.factor(GENDER), RACEN = as.factor(RACEN)) uid_final_data &lt;- final_data %&gt;% distinct(ID, .keep_all = TRUE) uid_final_data %&gt;% select(WT, AGE, GENDER, RACEN) %&gt;% summary %&gt;% kable WT AGE GENDER RACEN Min. :23.8 Min. :20.0 0:28 1:17 1st Qu.:26.6 1st Qu.:31.0 1:22 2: 8 Median :29.1 Median :39.5 NA 3:12 Mean :29.1 Mean :38.5 NA 4:13 3rd Qu.:31.3 3rd Qu.:48.0 NA NA Max. :36.8 Max. :59.0 NA NA Count the number of males/females in the dataset # be careful only 1 row per id if calculating this way uid_final_data %&gt;% nrow #&gt; [1] 50 # or n_distinct(uid_final_data$ID) #&gt; [1] 50 Count the number of subjects in each “Race” category uid_final_data %&gt;% group_by(RACEN) %&gt;% tally #&gt; # A tibble: 4 x 2 #&gt; RACEN n #&gt; &lt;fctr&gt; &lt;int&gt; #&gt; 1 1 17 #&gt; 2 2 8 #&gt; 3 3 12 #&gt; 4 4 13 calculate the min, mean, and max values for WT, AGE: by Gender uid_final_data %&gt;% select(GENDER, WT, AGE) %&gt;% group_by(GENDER) %&gt;% summarize_all(funs(min, mean, max)) %&gt;% kable GENDER WT_min AGE_min WT_mean AGE_mean WT_max AGE_max 0 23.8 20 27.0 37.0 31.4 51 1 29.2 28 31.8 40.5 36.8 59 b. by Race uid_final_data %&gt;% select(RACEN, WT, AGE) %&gt;% group_by(RACEN) %&gt;% summarize_all(funs(min, mean, max)) %&gt;% kable RACEN WT_min AGE_min WT_mean AGE_mean WT_max AGE_max 1 23.8 20 28.3 40.1 35.5 51 2 24.1 22 29.4 36.1 36.8 50 3 23.9 26 29.1 36.0 35.0 51 4 25.8 22 30.0 40.2 33.7 59 What is the Average numbers samples(observations) per individual in this dataset. Hint: make sure you are only counting samples, not necessarily all rows are observations! # don&#39;t want dosing observations final_data %&gt;% filter(is.na(AMT)) %&gt;% group_by(ID) %&gt;% summarize(num_obs = n()) %&gt;% summarize(avg_samples = mean(num_obs)) #&gt; # A tibble: 1 x 1 #&gt; avg_samples #&gt; &lt;dbl&gt; #&gt; 1 22 Calculate the Mean, 5th, and 95th percentile concentration at each time point for each formulation and dose level. hint: you can use ?quantile to calculate various quantiles final_data %&gt;% group_by(TIME) %&gt;% s_quantiles(COBS, probs = c(0.05, 0.5, 0.95)) %&gt;% kable TIME COBS_q5 COBS_q50 COBS_q95 0.00 NA NA NA 0.25 179528 1013450 6299400 0.50 315901 1339500 6196680 1.00 516881 1602900 4941020 2.00 661580 1556600 4623085 3.00 609477 1407150 4218805 4.00 538884 1237250 3752430 6.00 350257 882890 2881720 8.00 170944 736590 2139750 12.00 86539 372920 1449365 16.00 28623 198495 987036 24.00 3748 81368 550874 6.3 Nonstandard evaluation library(lazyeval) library(PKPDdatasets) library(PKPDmisc) library(tidyverse) #&gt; Loading tidyverse: ggplot2 #&gt; Loading tidyverse: tibble #&gt; Loading tidyverse: tidyr #&gt; Loading tidyverse: readr #&gt; Loading tidyverse: purrr #&gt; Loading tidyverse: dplyr #&gt; Conflicts with tidy packages ---------------------------------------------- #&gt; filter(): dplyr, stats #&gt; is_formula(): purrr, lazyeval #&gt; lag(): dplyr, stats eta_cov &lt;- read_csv(&quot;../data/EtaCov_base.csv&quot;) #&gt; Parsed with column specification: #&gt; cols( #&gt; Scenario = col_character(), #&gt; ID = col_integer(), #&gt; WT = col_integer(), #&gt; AGE = col_integer(), #&gt; nV = col_double(), #&gt; nCl = col_double(), #&gt; nKa = col_double() #&gt; ) lazyeval::interp() lazyeval::lazy_eval() This doesn’t work, as inside aes, ggplot literally evaluates the column names, so will look for the column called xtemplate, instead of Time x &lt;- &quot;Time&quot; y &lt;- &quot;Conc&quot; ggplot(df, aes(x=xtemplate, y=ytemplate, group = group_template)) + geom_line() + geom_point() conc_time &lt;- function(df, xcol, ycol, group_var) { p &lt;- lazyeval::interp(~ggplot(df, aes(x=xtemplate, y=ytemplate, group = group_template)) + geom_line() + geom_point() + theme_bw() + base_theme(), xtemplate = as.name(xcol), ytemplate = as.name(ycol), group_template = as.name(group_var)) return(lazyeval::lazy_eval(p)) } capitalize_names(Theoph) %&gt;% conc_time(&quot;TIME&quot;, &quot;CONC&quot;, &quot;SUBJECT&quot;) capitalize_names(sd_oral_richpk) %&gt;% conc_time(&quot;TIME&quot;, &quot;CONC&quot;, &quot;ID&quot;) + geom_hline(yintercept = 20, color = &quot;red&quot;) eta_vs_cov &lt;- function(df, xcol, ycol, group_var, facet_var) { p &lt;- lazyeval::interp(~ggplot(df, aes(x=xtemplate, y=ytemplate, group = group_template)) + geom_point() + facet_wrap(~facet_template) + stat_smooth(se = F) + theme_bw() + base_theme(), xtemplate = as.name(xcol), ytemplate = as.name(ycol), group_template = as.name(group_var), facet_template = as.name(facet_var)) return(lazyeval::lazy_eval(p)) } g_eta_cov &lt;- eta_cov %&gt;% gather(etaname, etaval, nV:nKa) g2_eta_cov &lt;- g_eta_cov %&gt;% gather(covname, covval, AGE, WT) eta_cov_list &lt;- g2_eta_cov %&gt;% split(.$covname) eta_cov_list %&gt;% lapply(eta_vs_cov, &quot;covval&quot;, &quot;etaval&quot;, group = &quot;etaval&quot;, &quot;etaname&quot;) #&gt; $AGE #&gt; `geom_smooth()` using method = &#39;loess&#39; #&gt; #&gt; $WT #&gt; `geom_smooth()` using method = &#39;loess&#39; cov_df &lt;- eta_cov %&gt;% select(WT:AGE) plot_list &lt;- list() for (name in names(cov_df)) { plot_list[[name]] &lt;- g_eta_cov %&gt;% eta_vs_cov(name, &quot;etaval&quot;, group = &quot;etaname&quot;, facet_var = &quot;etaname&quot;) } plot_list[[&quot;WT&quot;]] + geom_vline(xintercept = 80, color = &quot;red&quot;, size = 1.5) #&gt; `geom_smooth()` using method = &#39;loess&#39; lapply(plot_list, function(x) { # be aware that hard coded intercepts can run into issues with multiple plots #instead should use a list or named vector to setup the xintercept by cov name p &lt;- x + geom_vline(xintercept = 80, color = &quot;red&quot;, size = 1.5) return(p) }) #&gt; $WT #&gt; `geom_smooth()` using method = &#39;loess&#39; #&gt; #&gt; $AGE #&gt; `geom_smooth()` using method = &#39;loess&#39; 6.4 Diagnostic Plots read in the csv datasets: EtaCov_gathered Residuals Theta library(PKPDmisc) library(knitr) library(tidyverse) #&gt; Loading tidyverse: ggplot2 #&gt; Loading tidyverse: tibble #&gt; Loading tidyverse: tidyr #&gt; Loading tidyverse: readr #&gt; Loading tidyverse: purrr #&gt; Loading tidyverse: dplyr #&gt; Conflicts with tidy packages ---------------------------------------------- #&gt; filter(): dplyr, stats #&gt; lag(): dplyr, stats resid &lt;- read_phx(&quot;../data/Residuals.csv&quot;) theta &lt;- read_phx(&quot;../data/Theta.csv&quot;) etacov_gathered &lt;- read_phx(&quot;../data/EtaCov_gathered.csv&quot;) From the Theta table, create a reasonable quality output table of the results. Hint, use knitr::kable, in combination with results=‘asis’ in the chunk settings requires names: theta %&gt;% select(-one_of(c(&quot;Scenario&quot;, &quot;Var. Inf. factor&quot;))) %&gt;% kable(digits = 2) Parameter Estimate Units Stderr CV% 2.5% CI 97.5% CI tvKa 0.39 1/hr 0.02 4.05 0.36 0.42 tvV 2.94 0.05 1.83 2.83 3.04 tvCl 0.08 0.00 1.80 0.08 0.08 dVdWT 1.00 0.00 0.00 1.00 1.00 dCldAGE -0.87 0.11 -12.26 -1.09 -0.66 stdev0 0.10 0.00 2.80 0.09 0.10 clean up columns clean up column names units Create a CWRES vs Time plot with loess fits for the central tendency and the spread (hint abs() is your friend for the spread) gg_cwres_tad &lt;- function(df) { df %&gt;% ggplot(aes(x = TAD, y = CWRES)) + geom_point() + stat_smooth(method = &quot;loess&quot;, se=F, color = &quot;red&quot;) + stat_smooth(data = df %&gt;% mutate(CWRES = abs(CWRES)), se = F, color = &quot;blue&quot;) + stat_smooth(data = df %&gt;% mutate(CWRES = -abs(CWRES)), se = F, color = &quot;blue&quot;) + theme_bw() + base_theme() } gg_cwres_tad(resid) #&gt; `geom_smooth()` using method = &#39;loess&#39; #&gt; `geom_smooth()` using method = &#39;loess&#39; update the CWRES vs Time plot to flag anything with CWRES &gt; 2.5 as a red value resid %&gt;% mutate(HIGHCWRES = ifelse(abs(CWRES) &gt; 2.5, 1, 0)) %&gt;% ggplot(aes(x = TAD, y = CWRES)) + geom_point(aes(color = factor(HIGHCWRES))) + scale_color_manual(values = c(&quot;black&quot;, &quot;red&quot;), name = &quot;Outlier&quot;, labels = c(&quot;not outlier&quot;, &quot;outlier&quot;)) + stat_smooth(method = &quot;loess&quot;) + stat_smooth(data = resid %&gt;% mutate(CWRES = abs(CWRES)), method=&quot;loess&quot;, color = &quot;red&quot;, se = F) + stat_smooth(data = resid %&gt;% mutate(CWRES = -abs(CWRES)), method=&quot;loess&quot;, color = &quot;red&quot;, se = F) print a table of key information for all points with CWRES &gt; 2.5 resid %&gt;% mutate(HIGHCWRES = ifelse(abs(CWRES) &gt; 2.5, 1, 0)) %&gt;% filter(HIGHCWRES ==1) %&gt;% select(ID, IVAR, TAD, IPRED, DV) %&gt;% kable(digits = 2) ID IVAR TAD IPRED DV 4 364 28 28.93 18.62 4 400 64 11.92 13.73 5 48 0 7.26 8.12 9 352 16 39.54 27.48 36 3 3 23.60 17.10 36 364 28 18.01 22.57 Plot individual IPRED and DV vs time split_resid &lt;- resid %&gt;% filter(TADSeq ==1) %&gt;% mutate(IDBINS = ids_per_plot(ID, 9)) %&gt;% split(.[[&quot;IDBINS&quot;]]) p &lt;- function(df) { df %&gt;% ggplot(aes(x = TAD, y = IPRED, group= TADSeq)) + geom_line() + facet_wrap(~ID) + theme_bw() + geom_point(aes(x = TAD, y = DV))+ labs(list(x = &quot;Time after Dose, hrs&quot;, y = &quot;Individual Predicted and Observed&quot;)) } split_resid %&gt;% map(p) #&gt; $`1` #&gt; #&gt; $`2` #&gt; #&gt; $`3` #&gt; #&gt; $`4` #&gt; #&gt; $`5` #&gt; #&gt; $`6` As a reminder, map works like lapply, it applies the same function to each element in the list. In this case, it is taking split_resid (which is the residual dataframe split by 9 ids per group) and then applies the plot function to each set of 9. 6b) add the population prediction as a dashed blue line p &lt;- function(df) { df %&gt;% ggplot(aes(x = TAD, y = IPRED, group= TADSeq)) + geom_line() + facet_wrap(~ID) + theme_bw() + geom_point(aes(x = TAD, y = DV))+labs(list(x = &quot;Time after Dose, hrs&quot;, y = &quot;Individual Predicted and Observed&quot;)) + geom_line(aes(x = TAD, y = PRED, group = TADSeq), color = &quot;blue&quot;) } split_resid %&gt;% map(p) #&gt; $`1` #&gt; #&gt; $`2` #&gt; #&gt; $`3` #&gt; #&gt; $`4` #&gt; #&gt; $`5` #&gt; #&gt; $`6` With EtaCov_final create histograms of all the eta distributions p_etas&lt;- etacov_gathered %&gt;% ggplot(aes(x = VALUE, group = ETA)) + geom_histogram(fill = &quot;white&quot;, color = &quot;black&quot;) + facet_wrap(~ETA, scales = &quot;free&quot;) + base_theme() p_etas #&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. add a mean value for each eta overlaid on the above plot mean_eta &lt;- etacov_gathered %&gt;% group_by(ETA) %&gt;% summarize(meanEta = mean(VALUE)) p_etas + geom_vline(data = mean_eta, aes(xintercept = meanEta), size = 1.5, color = &quot;red&quot;) #&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Create Eta vs Covariate plots for each covariate and all etas etacov_gathered %&gt;% ggplot(aes(x = WT, y = VALUE, group = ETA)) + geom_point() + facet_wrap(~ETA, scales = &quot;free&quot;) + stat_smooth(method = &quot;loess&quot;, color = &quot;blue&quot;, se = F, size = 1.3) + base_theme() etacov_gathered %&gt;% ggplot(aes(x = AGE, y = VALUE, group = ETA)) + geom_point() + facet_wrap(~ETA, scales = &quot;free&quot;) + stat_smooth(method = &quot;loess&quot;, color = &quot;blue&quot;, se = F, size = 1.3) + base_theme() Note in the plot above, the choice of facet_wrap was arbitrary, and potentially a cleaner looking plot can be created with facet_grid, especially for labels, my suggestion is to try both. Hint: since there is so much duplicated, this would be a good opportunity to turn that into a function that you pass in the covariate to plot for x. add loess fits to the eta cov plots done in above plots "]
]
